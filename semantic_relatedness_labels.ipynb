{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from task import pubmed_task, nicta_task, dri_task, art_task, PUBMED_TASK, NICTA_TASK, DRI_TASK, ART_TASK \n",
    "from models import BertHSLN, BertHSLNMultiSeparateLayers\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from os import makedirs\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ADAPT: provide the paths to the models\n",
    "multi_groups_model_path = \"results/mult_grouped/0_0_6_model.pt\"\n",
    "multi_model_path = \"results/mult_all/0_0_10_model.pt\"\n",
    "pubmed_base_path = \"results/pubmed_base/0_0_model.pt\"\n",
    "nicta_base_path = \"results/nicta_base/0_0_model.pt\"\n",
    "dri_base_path = \"results/dri_base/0_0_model.pt\"\n",
    "art_base_path = \"results/art_base/0_0_model.pt\"\n",
    "\n",
    "# ADAPT: provide the path where to store the results (semantic vectors heatmaps and PCA results)\n",
    "results_out = \"results/correlations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "makedirs(results_out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_task(create_func):\n",
    "    return create_func(train_batch_size=32, max_docs=-1)\n",
    "\n",
    "\n",
    "def get_all_tasks():\n",
    "    tasks = []\n",
    "    tasks.append(create_task(pubmed_task))\n",
    "    tasks.append(create_task(nicta_task))\n",
    "    tasks.append(create_task(dri_task))\n",
    "    tasks.append(create_task(art_task))\n",
    "    return tasks\n",
    "\n",
    "\n",
    "def get_task(task_name):\n",
    "    for t in get_all_tasks():\n",
    "        if t.task_name == task_name:\n",
    "            return t\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, tasks, model_class=BertHSLN, config=dict()):\n",
    "    BERT_MODEL = \"bert_model/scibert_scivocab_uncased/\"\n",
    "    best_config = {\n",
    "        \"bert_model\": BERT_MODEL,\n",
    "        \"bert_trainable\": False,\n",
    "        \"model\": BertHSLN.__name__,\n",
    "        \"cacheable_tasks\": [],\n",
    "\n",
    "        \"dropout\": 0.5,\n",
    "        \"word_lstm_hs\": 758,\n",
    "        \"att_pooling_dim_ctx\": 200,\n",
    "        \"att_pooling_num_ctx\": 15,\n",
    "\n",
    "        \"lr\": 3e-05,\n",
    "        \"lr_epoch_decay\": 0.9,\n",
    "        \"batch_size\":  32,\n",
    "        \"max_seq_length\": 128,\n",
    "        \"max_epochs\": 20,\n",
    "        \"early_stopping\": 5\n",
    "    }\n",
    "    best_config.update(config)\n",
    "    \n",
    "    model = model_class(best_config, tasks)\n",
    "    params = torch.load(path, map_location=torch.device(\"cuda\"))\n",
    "    model.load_state_dict(params)        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "cpu_device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_groups_model_config = dict()\n",
    "multi_groups_model_config[\"attention_groups\"] = [[PUBMED_TASK, NICTA_TASK, ART_TASK, DRI_TASK]]\n",
    "multi_groups_model_config[\"sentence_encoder_groups\"] = [[PUBMED_TASK, NICTA_TASK], [ART_TASK, DRI_TASK]]\n",
    "multi_groups_model = load_model(multi_groups_model_path, get_all_tasks(), BertHSLNMultiSeparateLayers, multi_groups_model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = load_model(multi_model_path, get_all_tasks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_model = load_model(pubmed_base_path, [get_task(PUBMED_TASK)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nicta_model = load_model(nicta_base_path, [get_task(NICTA_TASK)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dri_model = load_model(dri_base_path, [get_task(DRI_TASK)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_model = load_model(art_base_path, [get_task(ART_TASK)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_and_map_predicted_values(true_labels, predicted_labels, true_label_names, pred_label_names):\n",
    "    assert len(true_labels) == len(predicted_labels)\n",
    "    cleared_predicted = []\n",
    "    cleared_true = []\n",
    "    for true_label, predicted_label in zip(true_labels, predicted_labels):\n",
    "        # filter masked labels (0)\n",
    "        if true_label > 0:\n",
    "            cleared_true.append(true_label_names[true_label])\n",
    "            cleared_predicted.append(pred_label_names[predicted_label])\n",
    "    return cleared_true, cleared_predicted\n",
    "\n",
    "\n",
    "def get_labels_matrix(tasks):\n",
    "    labels_matrix = dict()\n",
    "    for t1 in tasks:\n",
    "        for l1 in t1.get_labels_pres_titled():\n",
    "            l1 = t1.short_name + \":\" + l1\n",
    "            labels_matrix[l1] = dict()\n",
    "            for t2 in tasks:\n",
    "                for l2 in t2.get_labels_pres_titled():\n",
    "                    l2 = t2.short_name + \":\" + l2\n",
    "                    labels_matrix[l1][l2] = 0\n",
    "    return labels_matrix\n",
    "\n",
    "def normalize_values(tasks, labels_matrix):\n",
    "    '''Normalise the predicted counts within a task.'''\n",
    "    for t1 in tasks:\n",
    "        del labels_matrix[t1.short_name + \":Mask\"]\n",
    "        for l1 in t1.get_labels_titled()[1:]:\n",
    "            l1 = t1.short_name + \":\" + l1\n",
    "            predicted_labels = labels_matrix[l1]            \n",
    "            for t2 in tasks:\n",
    "                label_sum = 0\n",
    "                del predicted_labels[t2.short_name + \":Mask\"]\n",
    "                for l2 in t2.get_labels_titled()[1:]:\n",
    "                    l2 = t2.short_name + \":\" + l2\n",
    "                    label_sum += predicted_labels[l2]\n",
    "                for l2 in t2.get_labels_titled()[1:]:\n",
    "                    l2 = t2.short_name + \":\" + l2\n",
    "                    if label_sum != 0:\n",
    "                        predicted_labels[l2] = predicted_labels[l2] / label_sum\n",
    "                \n",
    "def predict_labels(eval_tasks, models):\n",
    "    labels_matrix = get_labels_matrix(get_all_tasks())\n",
    "    with torch.no_grad():                \n",
    "        for eval_task in eval_tasks: \n",
    "            print(f'evaluating task {eval_task.task_name}... ')                        \n",
    "            for mod in models:                \n",
    "                for fold in eval_task.get_folds()[0:1]: # predict labels of first fold only\n",
    "                    for batch in fold.test:\n",
    "                        tensor_dict_to_gpu(batch, device)\n",
    "\n",
    "                        if len(mod.crf.per_task_output.values()) == 1:\n",
    "                            #single task model\n",
    "                            orig_task = batch[\"task\"]\n",
    "                            batch[\"task\"] = list(mod.crf.per_task_output.keys())[0]\n",
    "                            output = mod(batch=batch, output_all_tasks=True)\n",
    "                            batch[\"task\"] = orig_task\n",
    "                        else:\n",
    "                            # multi-task model\n",
    "                            output = mod(batch=batch, output_all_tasks=True)\n",
    "\n",
    "                        true_labels = batch[\"label_ids\"].view(-1)\n",
    "                        for task_output in output[\"task_outputs\"]:\n",
    "                            t = get_task(task_output[\"task\"])\n",
    "                            pred_labels = task_output[\"predicted_label\"].view(-1)\n",
    "                            cleared_true, cleared_predicted = clear_and_map_predicted_values(true_labels, pred_labels, eval_task.get_labels_titled(), t.get_labels_titled())\n",
    "                            for true_label, pred_label in zip(cleared_true, cleared_predicted):\n",
    "                                true_label = eval_task.short_name + \":\" + true_label\n",
    "                                pred_label = t.short_name + \":\" + pred_label\n",
    "                                labels_matrix[true_label][pred_label] += 1                                                        \n",
    "\n",
    "                        tensor_dict_to_cpu(batch)\n",
    "    # normalize values\n",
    "    normalize_values(get_all_tasks(), labels_matrix)\n",
    "    # convert to format for pandas\n",
    "    result = []\n",
    "    for k, v in labels_matrix.items():\n",
    "        r = dict()\n",
    "        r[\"true_label\"] = k\n",
    "        r.update(v)\n",
    "        result.append(r)\n",
    "    return result\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model.to(device)\n",
    "multi_labels_matrix = predict_labels(get_all_tasks(), [multi_model])\n",
    "multi_model.to(cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_groups_model.to_device(device, device)\n",
    "multi_groups_labels_matrix = predict_labels(get_all_tasks(), [multi_groups_model])\n",
    "multi_groups_model.to_device(cpu_device, cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [pubmed_model, nicta_model, dri_model, art_model]\n",
    "for m in base_models:\n",
    "    m.to(device)\n",
    "base_labels_matrix = predict_labels(get_all_tasks(), base_models)\n",
    "for m in base_models:\n",
    "    m.to(cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_matrix_to_df(labels_matrix):\n",
    "    df = pd.DataFrame.from_dict(labels_matrix)\n",
    "    df = df.set_index(\"true_label\")\n",
    "    df = df.round(2)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULT GROUPED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_groups_df = labels_matrix_to_df(multi_groups_labels_matrix)\n",
    "multi_groups_df.to_csv(os.path.join(results_out, \"multi_groups_labels_matrix.csv\"))\n",
    "multi_groups_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULT ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_df = labels_matrix_to_df(multi_labels_matrix)\n",
    "multi_df.to_csv(os.path.join(results_out, \"multi_labels_matrix.csv\"))\n",
    "multi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = labels_matrix_to_df(base_labels_matrix)\n",
    "base_df.to_csv(os.path.join(results_out, \"base_labels_matrix.csv\"))\n",
    "base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULT GROUPED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "plt.figure(figsize = (22,14))\n",
    "ax = sns.heatmap(multi_groups_df, annot=True, linewidths=2, cmap=plt.cm.Blues)\n",
    "plt.savefig(os.path.join(results_out, \"multi_groups_heatmap.pdf\"), format=\"pdf\")\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULT ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "plt.figure(figsize = (22,14))\n",
    "ax = sns.heatmap(multi_df, annot=True, linewidths=2, cmap=plt.cm.Blues)\n",
    "plt.savefig(os.path.join(results_out, \"multi_heatmap.pdf\"), format=\"pdf\")\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "plt.figure(figsize = (22,14))\n",
    "ax = sns.heatmap(base_df, annot=True, linewidths=2, cmap=plt.cm.Blues)\n",
    "plt.savefig(os.path.join(results_out, \"base_heatmap.pdf\"), format=\"pdf\")\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pca(df):\n",
    "    pca = PCA(n_components=2)\n",
    "    X = pca.fit_transform(df)\n",
    "    x = X[:, 0]\n",
    "    y = X[:, 1]\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    plt.xlim(-1.5, 1.5)\n",
    "    plt.ylim(-1.5, 1.5)\n",
    "    ax.scatter(x, y, alpha=0.2)\n",
    "    for i, txt in enumerate(df.index):\n",
    "        ax.annotate(txt, (x[i], y[i]))\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"PCA_X\"] = x\n",
    "    df_copy[\"PCA_Y\"] = y\n",
    "    return X, ax, df_copy\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULT GROUPED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_groups_x, ax, multi_groups_pca_df = do_pca(multi_groups_df)\n",
    "multi_groups_pca_df.to_csv(os.path.join(results_out, \"multi_groups_corr.csv\"))\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULT ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_x, ax, multi_pca_df = do_pca(multi_df)\n",
    "multi_pca_df.to_csv(os.path.join(results_out, \"multi_corr.csv\"))\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_x, ax, base_pca_df = do_pca(base_df)\n",
    "base_pca_df.to_csv(os.path.join(results_out, \"base_corr.csv\"))\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
